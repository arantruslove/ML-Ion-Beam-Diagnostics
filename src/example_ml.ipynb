{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example notebook that:\n",
    "\n",
    "### 1. Trains a CNN on laser-driven ion beam images labeled with their beam parameters\n",
    "### 2. Trains a CNN to categorise each image based on how accurately the previous network was able to determine the beam parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from machine_learning.keras_trial import ml_trial\n",
    "from analysis.analyser import Analyser, print_error_rates\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../shared_data/50Kelectrons.pickle\", \"rb\") as file:\n",
    "    images_and_labels = pickle.load(file)\n",
    "\n",
    "\n",
    "images = np.array(images_and_labels[\"images\"])\n",
    "labels = np.array(images_and_labels[\"labels\"])[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 29019\n",
    "print(labels[index])\n",
    "plt.imshow(images[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking log of the number of protons and electrons to ensure a more linearly even distribution when normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:, 2] = np.log10(labels[:, 2])\n",
    "labels[:, 4] = np.log10(labels[:, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalising the Images and Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_scaler = utils.DynamicMinMaxScaler()\n",
    "labels_scaler = utils.DynamicMinMaxScaler()\n",
    "norm_images = images_scaler.fit_transform(images)\n",
    "norm_labels = labels_scaler.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and validation datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_TRAIN = 3 / 4\n",
    "n_train = int(FRAC_TRAIN * len(norm_images))\n",
    "\n",
    "\n",
    "n_validate = len(norm_images) - n_train\n",
    "\n",
    "\n",
    "x_train = norm_images[0:n_train]\n",
    "\n",
    "\n",
    "y_train = norm_labels[0:n_train]\n",
    "\n",
    "\n",
    "x_test = norm_images[n_train : n_train + n_validate]\n",
    "\n",
    "\n",
    "y_test = norm_labels[n_train : n_train + n_validate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE = 15\n",
    "val_loss, model = ml_trial(\n",
    "    x_train, y_train, x_test, y_test, BATCH_SIZE, MAX_EPOCHS, patience=PATIENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restoring Original Label Sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = labels_scaler.inverse_transform(y_test)\n",
    "predictions = labels_scaler.inverse_transform(norm_predictions)\n",
    "true_labels[:, 2] = 10 ** true_labels[:, 2]\n",
    "predictions[:, 2] = 10 ** predictions[:, 2]\n",
    "true_labels[:, 4] = 10 ** true_labels[:, 4]\n",
    "predictions[:, 4] = 10 ** predictions[:, 4]\n",
    "\n",
    "images_labels = {\"images\": x_test, \"labels\": true_labels, \"predictions\": predictions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the mean relative absolute errors for each parameter and the loss diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = Analyser(\n",
    "    images_labels,\n",
    "    [\"Proton E Max.\", \"Proton Temp.\", \"Proton N0\", \"Electron Temp.\", \"Electron N0\"],\n",
    ")\n",
    "\n",
    "\n",
    "analyser.histogram_2d()\n",
    "\n",
    "\n",
    "mraes = analyser.mraes()\n",
    "\n",
    "\n",
    "print(mraes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoring each image based on whether any of the parameters are above the relative absolute error threshold:\n",
    "\n",
    "Proton Emax: 20%\n",
    "\n",
    "Proton Temperature: 20%\n",
    "\n",
    "Proton Number: 50%\n",
    "\n",
    "Will be labelled 1 if any parameters exceed the thresholds above and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_cats = analyser.categorise_by_threshold([0.2, 0.2, 0.5])\n",
    "bin_images = images_cats[\"images\"]\n",
    "bin_labels = images_cats[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of images labelled 1 and the number labelled 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positives = 0\n",
    "for label in bin_labels:\n",
    "    if label[0] == 1:\n",
    "        n_positives += 1\n",
    "\n",
    "print(f\"No. 1s: {n_positives}\")\n",
    "print(f\"No. 0s: {len(bin_labels) - n_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_TRAIN = 3 / 4\n",
    "n_train = int(FRAC_TRAIN * len(bin_images))\n",
    "\n",
    "\n",
    "n_validate = len(bin_images) - n_train\n",
    "\n",
    "\n",
    "x_train = bin_images[0:n_train]\n",
    "\n",
    "\n",
    "y_train = bin_labels[0:n_train]\n",
    "\n",
    "\n",
    "x_test = bin_images[n_train : n_train + n_validate]\n",
    "\n",
    "\n",
    "y_test = bin_labels[n_train : n_train + n_validate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a binary classifier CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 10\n",
    "val_loss, categoriser = ml_trial(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    BATCH_SIZE,\n",
    "    MAX_EPOCHS,\n",
    "    patience=15,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    out_activation=\"sigmoid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapsing the predictions to 0 or 1 based on a user specified cutoff\n",
    "\n",
    "1 if prediction >= CUTOFF\n",
    "\n",
    "0 if prediction < CUTOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF = 0.5\n",
    "predictions = categoriser.predict(x_test)\n",
    "predictions = np.array([1 if prediction >= CUTOFF else 0 for prediction in predictions])\n",
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_error_rates(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_site",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
